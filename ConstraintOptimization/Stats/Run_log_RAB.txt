Epoch [1/300], Train Loss: 1.6491, Train Acc: 39.10%
Epoch [2/300], Train Loss: 1.1741, Train Acc: 57.44%
Epoch [3/300], Train Loss: 0.9382, Train Acc: 66.78%
Epoch [4/300], Train Loss: 0.7801, Train Acc: 72.41%
Epoch [5/300], Train Loss: 0.6783, Train Acc: 76.40%
Epoch [6/300], Train Loss: 0.6188, Train Acc: 78.76%
Epoch [7/300], Train Loss: 0.5619, Train Acc: 80.56%
Epoch [8/300], Train Loss: 0.5355, Train Acc: 81.64%
Epoch [9/300], Train Loss: 0.5033, Train Acc: 82.83%
Epoch [10/300], Train Loss: 0.4882, Train Acc: 83.31%
Epoch [11/300], Train Loss: 0.4702, Train Acc: 83.94%
Epoch [12/300], Train Loss: 0.4521, Train Acc: 84.62%
Epoch [13/300], Train Loss: 0.4459, Train Acc: 84.66%
Epoch [14/300], Train Loss: 0.4322, Train Acc: 85.42%
Epoch [15/300], Train Loss: 0.4220, Train Acc: 85.58%
Epoch [16/300], Train Loss: 0.4122, Train Acc: 85.77%
Epoch [17/300], Train Loss: 0.4026, Train Acc: 86.33%
Epoch [18/300], Train Loss: 0.3990, Train Acc: 86.11%
Epoch [19/300], Train Loss: 0.3938, Train Acc: 86.51%
Epoch [20/300], Train Loss: 0.3796, Train Acc: 86.86%
Epoch [21/300], Train Loss: 0.3772, Train Acc: 87.14%
Epoch [22/300], Train Loss: 0.3729, Train Acc: 87.17%
Epoch [23/300], Train Loss: 0.3693, Train Acc: 87.46%
Epoch [24/300], Train Loss: 0.3637, Train Acc: 87.72%
Epoch [25/300], Train Loss: 0.3633, Train Acc: 87.48%
Epoch [26/300], Train Loss: 0.3593, Train Acc: 87.91%
Epoch [27/300], Train Loss: 0.3546, Train Acc: 87.82%
Epoch [28/300], Train Loss: 0.3525, Train Acc: 88.08%
Epoch [29/300], Train Loss: 0.3510, Train Acc: 88.06%
Epoch [30/300], Train Loss: 0.3492, Train Acc: 88.17%
Epoch [31/300], Train Loss: 0.3422, Train Acc: 88.47%
Epoch [32/300], Train Loss: 0.3456, Train Acc: 88.08%
Epoch [33/300], Train Loss: 0.3328, Train Acc: 88.62%
Epoch [34/300], Train Loss: 0.3411, Train Acc: 88.33%
Epoch [35/300], Train Loss: 0.3389, Train Acc: 88.41%
Epoch [36/300], Train Loss: 0.3310, Train Acc: 88.63%
Epoch [37/300], Train Loss: 0.3283, Train Acc: 88.84%
Epoch [38/300], Train Loss: 0.3318, Train Acc: 88.59%
Epoch [39/300], Train Loss: 0.3302, Train Acc: 88.77%
Epoch [40/300], Train Loss: 0.3314, Train Acc: 88.66%
Epoch [41/300], Train Loss: 0.3240, Train Acc: 89.07%
Epoch [42/300], Train Loss: 0.3179, Train Acc: 89.22%
Epoch [43/300], Train Loss: 0.3222, Train Acc: 89.05%
Epoch [44/300], Train Loss: 0.3228, Train Acc: 89.30%
Epoch [45/300], Train Loss: 0.3237, Train Acc: 88.92%
Epoch [46/300], Train Loss: 0.3222, Train Acc: 89.07%
Epoch [47/300], Train Loss: 0.3202, Train Acc: 89.19%
Epoch [48/300], Train Loss: 0.3149, Train Acc: 89.20%
Epoch [49/300], Train Loss: 0.3173, Train Acc: 88.99%
Epoch [50/300], Train Loss: 0.3135, Train Acc: 89.19%
Epoch [51/300], Train Loss: 0.3234, Train Acc: 89.00%
Epoch [52/300], Train Loss: 0.3139, Train Acc: 89.19%
Epoch [53/300], Train Loss: 0.3174, Train Acc: 89.03%
Epoch [54/300], Train Loss: 0.3182, Train Acc: 89.16%
Epoch [55/300], Train Loss: 0.3085, Train Acc: 89.65%
Epoch [56/300], Train Loss: 0.3184, Train Acc: 89.21%
Epoch [57/300], Train Loss: 0.3067, Train Acc: 89.55%
Epoch [58/300], Train Loss: 0.3128, Train Acc: 89.42%
Epoch [59/300], Train Loss: 0.3089, Train Acc: 89.58%
Epoch [60/300], Train Loss: 0.3078, Train Acc: 89.52%
Epoch [61/300], Train Loss: 0.3070, Train Acc: 89.47%
Epoch [62/300], Train Loss: 0.3009, Train Acc: 89.78%
Epoch [63/300], Train Loss: 0.3079, Train Acc: 89.54%
Epoch [64/300], Train Loss: 0.3066, Train Acc: 89.63%
Epoch [65/300], Train Loss: 0.3112, Train Acc: 89.38%
Epoch [66/300], Train Loss: 0.3108, Train Acc: 89.45%
Epoch [67/300], Train Loss: 0.3000, Train Acc: 89.78%
Epoch [68/300], Train Loss: 0.3119, Train Acc: 89.38%
Epoch [69/300], Train Loss: 0.3096, Train Acc: 89.36%
Epoch [70/300], Train Loss: 0.3004, Train Acc: 89.68%
Epoch [71/300], Train Loss: 0.3015, Train Acc: 89.68%
Epoch [72/300], Train Loss: 0.3150, Train Acc: 89.20%
Epoch [73/300], Train Loss: 0.3083, Train Acc: 89.56%
Epoch [74/300], Train Loss: 0.3022, Train Acc: 89.75%
Epoch [75/300], Train Loss: 0.3024, Train Acc: 89.73%
Epoch [76/300], Train Loss: 0.3085, Train Acc: 89.46%
Epoch [77/300], Train Loss: 0.2988, Train Acc: 89.95%
Epoch [78/300], Train Loss: 0.3020, Train Acc: 89.73%
Epoch [79/300], Train Loss: 0.3013, Train Acc: 89.71%
Epoch [80/300], Train Loss: 0.2971, Train Acc: 89.83%
Epoch [81/300], Train Loss: 0.2956, Train Acc: 89.98%
Epoch [82/300], Train Loss: 0.2939, Train Acc: 90.05%
Epoch [83/300], Train Loss: 0.3048, Train Acc: 89.67%
Epoch [84/300], Train Loss: 0.3056, Train Acc: 89.51%
Epoch [85/300], Train Loss: 0.2940, Train Acc: 89.95%
Epoch [86/300], Train Loss: 0.3012, Train Acc: 89.66%
Epoch [87/300], Train Loss: 0.2979, Train Acc: 89.78%
Epoch [88/300], Train Loss: 0.2892, Train Acc: 90.16%
Epoch [89/300], Train Loss: 0.2983, Train Acc: 89.94%
Epoch [90/300], Train Loss: 0.2996, Train Acc: 89.83%
Epoch [91/300], Train Loss: 0.2978, Train Acc: 89.75%
Epoch [92/300], Train Loss: 0.2968, Train Acc: 90.00%
Epoch [93/300], Train Loss: 0.2953, Train Acc: 89.93%
Epoch [94/300], Train Loss: 0.2972, Train Acc: 89.90%
Epoch [95/300], Train Loss: 0.2943, Train Acc: 89.91%
Epoch [96/300], Train Loss: 0.2935, Train Acc: 90.02%
Epoch [97/300], Train Loss: 0.3069, Train Acc: 89.38%
Epoch [98/300], Train Loss: 0.3008, Train Acc: 89.68%
Epoch [99/300], Train Loss: 0.2969, Train Acc: 89.86%
Epoch [100/300], Train Loss: 0.2932, Train Acc: 89.98%
Epoch [101/300], Train Loss: 0.2988, Train Acc: 89.78%
Epoch [102/300], Train Loss: 0.2949, Train Acc: 90.02%
Epoch [103/300], Train Loss: 0.2911, Train Acc: 90.05%
Epoch [104/300], Train Loss: 0.2949, Train Acc: 90.03%
Epoch [105/300], Train Loss: 0.2954, Train Acc: 89.97%
Epoch [106/300], Train Loss: 0.2948, Train Acc: 90.01%
Epoch [107/300], Train Loss: 0.3000, Train Acc: 89.74%
Epoch [108/300], Train Loss: 0.2944, Train Acc: 89.83%
Epoch [109/300], Train Loss: 0.2927, Train Acc: 90.11%
Epoch [110/300], Train Loss: 0.2911, Train Acc: 90.03%
Epoch [111/300], Train Loss: 0.2929, Train Acc: 89.89%
Epoch [112/300], Train Loss: 0.2954, Train Acc: 89.95%
Epoch [113/300], Train Loss: 0.2930, Train Acc: 89.86%
Epoch [114/300], Train Loss: 0.2883, Train Acc: 90.31%
Epoch [115/300], Train Loss: 0.2964, Train Acc: 90.05%
Epoch [116/300], Train Loss: 0.2969, Train Acc: 89.83%
Epoch [117/300], Train Loss: 0.2914, Train Acc: 89.92%
Epoch [118/300], Train Loss: 0.2845, Train Acc: 90.48%
Epoch [119/300], Train Loss: 0.2873, Train Acc: 90.17%
Epoch [120/300], Train Loss: 0.2955, Train Acc: 89.93%
Epoch [121/300], Train Loss: 0.2964, Train Acc: 89.97%
Epoch [122/300], Train Loss: 0.2946, Train Acc: 90.01%
Epoch [123/300], Train Loss: 0.2882, Train Acc: 90.05%
Epoch [124/300], Train Loss: 0.2875, Train Acc: 90.15%
Epoch [125/300], Train Loss: 0.2891, Train Acc: 90.26%
Epoch [126/300], Train Loss: 0.2885, Train Acc: 90.11%
Epoch [127/300], Train Loss: 0.2915, Train Acc: 90.07%
Epoch [128/300], Train Loss: 0.2838, Train Acc: 90.28%
Epoch [129/300], Train Loss: 0.2880, Train Acc: 90.26%
Epoch [130/300], Train Loss: 0.2952, Train Acc: 89.95%
Epoch [131/300], Train Loss: 0.2897, Train Acc: 90.03%
Epoch [132/300], Train Loss: 0.2883, Train Acc: 90.40%
Epoch [133/300], Train Loss: 0.2921, Train Acc: 89.98%
Epoch [134/300], Train Loss: 0.2851, Train Acc: 90.35%
Epoch [135/300], Train Loss: 0.2947, Train Acc: 90.12%
Epoch [136/300], Train Loss: 0.2848, Train Acc: 90.22%
Epoch [137/300], Train Loss: 0.2926, Train Acc: 90.19%
Epoch [138/300], Train Loss: 0.2900, Train Acc: 90.14%
Epoch [139/300], Train Loss: 0.2892, Train Acc: 90.22%
Epoch [140/300], Train Loss: 0.2812, Train Acc: 90.52%
Epoch [141/300], Train Loss: 0.2983, Train Acc: 89.87%
Epoch [142/300], Train Loss: 0.2862, Train Acc: 90.33%
Epoch [143/300], Train Loss: 0.2858, Train Acc: 90.26%
Epoch [144/300], Train Loss: 0.2929, Train Acc: 90.20%
Epoch [145/300], Train Loss: 0.2858, Train Acc: 90.13%
Epoch [146/300], Train Loss: 0.2841, Train Acc: 90.43%
Epoch [147/300], Train Loss: 0.2819, Train Acc: 90.48%
Epoch [148/300], Train Loss: 0.2888, Train Acc: 90.19%
Epoch [149/300], Train Loss: 0.2964, Train Acc: 89.77%
Epoch [150/300], Train Loss: 0.2835, Train Acc: 90.39%
Epoch [151/300], Train Loss: 0.1475, Train Acc: 95.07%
Epoch [152/300], Train Loss: 0.0991, Train Acc: 96.71%
Epoch [153/300], Train Loss: 0.0806, Train Acc: 97.26%
Epoch [154/300], Train Loss: 0.0699, Train Acc: 97.71%
Epoch [155/300], Train Loss: 0.0588, Train Acc: 98.07%
Epoch [156/300], Train Loss: 0.0509, Train Acc: 98.32%
Epoch [157/300], Train Loss: 0.0447, Train Acc: 98.59%
Epoch [158/300], Train Loss: 0.0413, Train Acc: 98.65%
Epoch [159/300], Train Loss: 0.0381, Train Acc: 98.77%
Epoch [160/300], Train Loss: 0.0322, Train Acc: 99.01%
Epoch [161/300], Train Loss: 0.0306, Train Acc: 99.05%
Epoch [162/300], Train Loss: 0.0270, Train Acc: 99.13%
Early stopping at epoch 162. Best was epoch 152 (val_loss=0.2366).
Restored best model from epoch 152.
Test Accuracy: 92.56%
Using device: cuda
Loaded model for run 2 from checkpoint.
Saved FC inputs for run 2.
Training and Validation Accuracy before Gurobi optimization: 97.6675 92.21
Training and Validation Accuracy of loaded inputs: (np.float64(0.975175), np.float64(0.9227))
Loaded inputs for Gurobi optimization.
Set parameter Username
Set parameter LicenseID to value 2677321
Academic license - for non-commercial use only - expires 2026-06-11
Set parameter TimeLimit to value 10800
Size of X: (40000, 256)
Size of W: (10, 256)
Size of b: (10,)
Mismatch:  0
Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (linux64 - "Ubuntu 18.04.6 LTS")

CPU model: Intel(R) Core(TM) i7-8700K CPU @ 3.70GHz, instruction set [SSE2|AVX|AVX2]
Thread count: 6 physical cores, 12 logical processors, using up to 12 threads

Non-default parameters:
TimeLimit  10800

Optimize a model with 760000 rows, 402570 columns and 87908720 nonzeros
Model fingerprint: 0x76e07ff0
Coefficient statistics:
  Matrix range     [4e-09, 4e+00]
  Objective range  [1e+00, 1e+00]
  Bounds range     [0e+00, 0e+00]
  RHS range        [1e-05, 2e+01]
Presolve removed 0 rows and 0 columns (presolve time = 7s)...
Presolve removed 0 rows and 0 columns (presolve time = 10s)...
Presolve removed 10000 rows and 10000 columns (presolve time = 16s)...
Presolve removed 50000 rows and 50000 columns (presolve time = 21s)...
Presolve removed 90000 rows and 90000 columns (presolve time = 26s)...
Presolve removed 130000 rows and 130000 columns (presolve time = 32s)...
Presolve removed 170000 rows and 170000 columns (presolve time = 38s)...
Presolve removed 210000 rows and 210000 columns (presolve time = 44s)...
Presolve removed 250000 rows and 250000 columns (presolve time = 51s)...
Presolve removed 300000 rows and 300000 columns (presolve time = 59s)...
Presolve removed 340000 rows and 340000 columns (presolve time = 66s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 77s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 96s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 100s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 105s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 111s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 115s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 120s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 125s)...
Presolve removed 360000 rows and 360000 columns (presolve time = 607s)...
Presolve removed 360000 rows and 360000 columns
Presolve time: 691.84s
Presolved: 42570 rows, 400000 columns, 87188720 nonzeros

Concurrent LP optimizer: primal simplex, dual simplex, and barrier
Showing barrier log only...

Ordering time: 4.31s
Elapsed ordering time = 6s
Elapsed ordering time = 9s
Elapsed ordering time = 11s
Elapsed ordering time = 13s
Elapsed ordering time = 15s
Ordering time: 16.73s

Barrier statistics:
 AA' NZ     : 8.712e+07
 Factor NZ  : 5.302e+08 (roughly 4.5 GB of memory)
 Factor Ops : 1.088e+13 (roughly 90 seconds per iteration)
 Threads    : 4

                  Objective                Residual
Iter       Primal          Dual         Primal    Dual     Compl     Time
   0  -8.29046926e+07 -1.01940102e+03  9.61e+07 1.26e+00  9.72e+04   804s
   1  -2.36195668e+07  2.12147586e+05  2.80e+07 3.71e+00  2.87e+04   806s
   2  -6.83393230e+06  3.14816162e+05  8.33e+06 2.95e+00  9.24e+03   808s
   3  -2.22111113e+06  3.75615763e+05  2.60e+06 2.07e+00  3.53e+03   809s
   4  -7.88101710e+05  3.90400262e+05  9.48e+05 1.28e+00  1.57e+03   811s
   5  -3.00348888e+05  3.47648478e+05  3.77e+05 7.55e-01  6.35e+02   813s
   6  -1.15581251e+05  2.99464443e+05  1.59e+05 5.60e-01  3.18e+02   816s
   7  -5.65464478e+04  2.30043050e+05  8.53e+04 3.90e-01  1.90e+02   819s
   8  -2.34094818e+04  1.36978431e+05  3.53e+04 2.27e-01  1.00e+02   941s
   9  -8.74410518e+03  8.80277233e+04  1.32e+04 1.35e-01  5.15e+01  1063s
  10  -4.04359653e+03  5.25954450e+04  6.10e+03 6.34e-02  2.65e+01  1186s
  11  -3.98192259e+02  1.59963939e+04  6.02e+02 1.10e-02  6.28e+00  1310s
  12   5.89060206e-01  1.37587783e+03  1.82e-06 4.51e-04  5.04e-01  1434s
  13   5.89431780e-01  5.95961032e+00  1.61e-05 1.36e-06  1.95e-03  1555s
  14   6.47334125e-01  3.38736140e+00  5.10e-07 5.61e-07  9.97e-04  1679s
  15   7.62743915e-01  2.40892862e+00  1.54e-06 3.85e-07  6.00e-04  1804s
  16   9.39322435e-01  1.98637587e+00  1.00e-06 2.21e-07  3.82e-04  1942s
  17   1.17430391e+00  1.82876224e+00  5.53e-07 1.32e-07  2.40e-04  2082s
  18   1.36580569e+00  1.75658195e+00  3.21e-07 7.15e-08  1.43e-04  2218s
  19   1.52929533e+00  1.72684497e+00  1.79e-07 3.56e-08  7.28e-05  2356s
  20   1.63727908e+00  1.71023141e+00  8.80e-08 1.28e-08  2.69e-05  2492s
  21   1.68976218e+00  1.70213224e+00  8.06e-08 2.03e-09  4.57e-06  2636s
  22   1.69877535e+00  1.70047239e+00  1.40e-07 2.90e-10  6.30e-07  2780s
  23   1.69994499e+00  1.70017134e+00  4.09e-08 2.45e-11  8.28e-08  2935s
  24   1.70010749e+00  1.70012374e+00  1.17e-06 1.44e-11  5.92e-09  3113s
  25   1.70011639e+00  1.70011748e+00  2.54e-07 1.36e-11  4.71e-10  3260s
  26   1.70011728e+00  1.70011717e+00  1.79e-07 1.55e-11  2.91e-11  3432s
  27   1.70011737e+00  1.70011717e+00  1.50e-07 1.48e-11  4.08e-13  3567s

Barrier solved model in 27 iterations and 3567.33 seconds (2645.32 work units)
Optimal objective 1.70011737e+00

Crossover log...

Warning: 5 variables dropped from basis

Restart crossover...

   40013 variables added to crossover basis                     3575s

    2405 DPushes remaining with DInf 0.0000000e+00              3576s
    2282 DPushes remaining with DInf 0.0000000e+00              3580s
    2159 DPushes remaining with DInf 0.0000000e+00              3585s
    2036 DPushes remaining with DInf 0.0000000e+00              3592s
    1913 DPushes remaining with DInf 0.0000000e+00              3600s
    1790 DPushes remaining with DInf 0.0000000e+00              3609s
    1667 DPushes remaining with DInf 0.0000000e+00              3620s
    1547 DPushes remaining with DInf 0.0000000e+00              3633s
    1437 DPushes remaining with DInf 0.0000000e+00              3646s
    1337 DPushes remaining with DInf 0.0000000e+00              3658s
    1247 DPushes remaining with DInf 0.0000000e+00              3670s
    1157 DPushes remaining with DInf 0.0000000e+00              3683s
    1077 DPushes remaining with DInf 0.0000000e+00              3696s
     997 DPushes remaining with DInf 0.0000000e+00              3709s
     917 DPushes remaining with DInf 0.0000000e+00              3722s
     847 DPushes remaining with DInf 0.0000000e+00              3735s
     777 DPushes remaining with DInf 0.0000000e+00              3748s
     707 DPushes remaining with DInf 0.0000000e+00              3761s
     637 DPushes remaining with DInf 0.0000000e+00              3775s
     577 DPushes remaining with DInf 0.0000000e+00              3788s
     517 DPushes remaining with DInf 0.0000000e+00              3801s
     457 DPushes remaining with DInf 0.0000000e+00              3814s
     397 DPushes remaining with DInf 0.0000000e+00              3828s
     337 DPushes remaining with DInf 1.2867122e-06              3842s
     277 DPushes remaining with DInf 6.6156106e-06              3857s
     257 DPushes remaining with DInf 5.7368737e-06              3862s

     208 PPushes remaining with PInf 5.6147213e-03              3908s
      65 PPushes remaining with PInf 1.6445171e-04              3910s
       0 PPushes remaining with PInf 0.0000000e+00              3912s

  Push phase complete: Pinf 0.0000000e+00, Dinf 3.4579339e-10   3912s


Solved with barrier
Iteration    Objective       Primal Inf.    Dual Inf.      Time
    2359    1.7001173e+00   0.000000e+00   1.463366e-10   3936s

Solved in 2359 iterations and 3948.91 seconds (3066.73 work units)
Optimal objective  1.700117341e+00
Total misclassified samples: 0
